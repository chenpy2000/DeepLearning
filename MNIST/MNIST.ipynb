{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321d41d1",
   "metadata": {},
   "source": [
    "<h1>MNIST</h1>\n",
    "<h2>Author: Xavier Chen</h2>\n",
    "\n",
    "This notebook plays around traditional MNIST Dataset. The goal is to learn basic machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef977dbc",
   "metadata": {},
   "source": [
    "# Index\n",
    "- [Linear Optimization](#1.-Introduction)\n",
    "- [Linear Regression](#1.-Introduction)\n",
    "- [Convolutional Neural Network](#Convolutional-Neural-Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716fbc38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6348d03f-195e-4662-b705-6a9831e639a6",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e9f892-8da2-4140-8b8b-4ab3eafc0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f47451-d8e5-4e46-89eb-9100c535781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb51de1-c4a5-4796-934b-0e467878e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc75785f-aa28-4501-8d10-583886cfb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df25f81b-6f1f-4e52-82f6-c3f928b2454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8bde80-4205-45cb-8025-4f3a67988481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}[{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf0e6f6-cc15-4b40-a13e-3112f56f346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      " ---------------------\n",
      "loss: 2.310675[   64/60000]\n",
      "loss: 2.275223[ 6464/60000]\n",
      "loss: 2.275768[12864/60000]\n",
      "loss: 2.255721[19264/60000]\n",
      "loss: 2.256931[25664/60000]\n",
      "loss: 2.240471[32064/60000]\n",
      "loss: 2.199592[38464/60000]\n",
      "loss: 2.214010[44864/60000]\n",
      "loss: 2.178637[51264/60000]\n",
      "loss: 2.150382[57664/60000]\n",
      "Epoch 2 \n",
      " ---------------------\n",
      "loss: 2.140564[   64/60000]\n",
      "loss: 2.099251[ 6464/60000]\n",
      "loss: 2.128566[12864/60000]\n",
      "loss: 2.039734[19264/60000]\n",
      "loss: 2.061405[25664/60000]\n",
      "loss: 2.046705[32064/60000]\n",
      "loss: 1.978005[38464/60000]\n",
      "loss: 2.043332[44864/60000]\n",
      "loss: 1.950029[51264/60000]\n",
      "loss: 1.907637[57664/60000]\n",
      "Epoch 3 \n",
      " ---------------------\n",
      "loss: 1.901038[   64/60000]\n",
      "loss: 1.841756[ 6464/60000]\n",
      "loss: 1.904348[12864/60000]\n",
      "loss: 1.749574[19264/60000]\n",
      "loss: 1.785492[25664/60000]\n",
      "loss: 1.773315[32064/60000]\n",
      "loss: 1.677769[38464/60000]\n",
      "loss: 1.796434[44864/60000]\n",
      "loss: 1.654277[51264/60000]\n",
      "loss: 1.609735[57664/60000]\n",
      "Epoch 4 \n",
      " ---------------------\n",
      "loss: 1.603702[   64/60000]\n",
      "loss: 1.520485[ 6464/60000]\n",
      "loss: 1.615887[12864/60000]\n",
      "loss: 1.427297[19264/60000]\n",
      "loss: 1.463253[25664/60000]\n",
      "loss: 1.461406[32064/60000]\n",
      "loss: 1.356818[38464/60000]\n",
      "loss: 1.520541[44864/60000]\n",
      "loss: 1.358223[51264/60000]\n",
      "loss: 1.317822[57664/60000]\n",
      "Epoch 5 \n",
      " ---------------------\n",
      "loss: 1.319214[   64/60000]\n",
      "loss: 1.214802[ 6464/60000]\n",
      "loss: 1.323684[12864/60000]\n",
      "loss: 1.151055[19264/60000]\n",
      "loss: 1.172390[25664/60000]\n",
      "loss: 1.185434[32064/60000]\n",
      "loss: 1.087639[38464/60000]\n",
      "loss: 1.275412[44864/60000]\n",
      "loss: 1.124843[51264/60000]\n",
      "loss: 1.089060[57664/60000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} \\n ---------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a9cf6",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "[Back to top](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d425994-5d83-4b30-968c-791ed0bb22a4",
   "metadata": {},
   "source": [
    "## 1 import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fa3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Libraries for Recovery\n",
    "##################################################\n",
    "\n",
    "import torch\n",
    "import torchvision ## Contains some utilities for working with the image data\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4a5cf-e935-4689-8289-b3cc20fd5b5c",
   "metadata": {},
   "source": [
    "## 2 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d75c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MNIST(root = 'data/', download = True)\n",
    "image, label = dataset[667]\n",
    "plt.imshow(image, cmap = 'gray') # Type : PIL.Image.Image\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3489c991-da7b-4324-ac5c-7fca3ded22b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x216b290f280>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_dataset = MNIST(root = 'data/', train = True, transform = transforms.ToTensor())\n",
    "image_tensor, label = mnist_dataset[0]\n",
    "print(image_tensor.shape, label)\n",
    "plt.imshow(image_tensor[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35d1ff6a-475f-45f3-a7c8-685e9388eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = random_split(mnist_dataset, [50000, 10000])\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(validation_data, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fe9d1c-0a81-49fb-bfaa-a57695c9d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "Parameter containing:\n",
      "tensor([[-0.0163, -0.0282,  0.0225,  ...,  0.0306, -0.0216,  0.0292],\n",
      "        [-0.0215, -0.0303, -0.0103,  ...,  0.0190, -0.0312, -0.0018],\n",
      "        [ 0.0057,  0.0233,  0.0299,  ..., -0.0010, -0.0278, -0.0233],\n",
      "        ...,\n",
      "        [-0.0005, -0.0130,  0.0241,  ...,  0.0354, -0.0220, -0.0307],\n",
      "        [-0.0023, -0.0282,  0.0230,  ...,  0.0085,  0.0331, -0.0210],\n",
      "        [-0.0324, -0.0235, -0.0160,  ..., -0.0273,  0.0167,  0.0133]],\n",
      "       requires_grad=True)\n",
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.0139, -0.0252,  0.0346, -0.0137,  0.0043,  0.0082, -0.0239, -0.0296,\n",
      "        -0.0286, -0.0135], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "\n",
    "## Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "print(model.weight.shape)\n",
    "print(model.weight)\n",
    "print(model.bias.shape)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b624144-2f0f-437b-b305-a6c6fe762202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 8, 2, 8, 7, 3, 8, 8, 1, 5, 8, 3, 6, 5, 9, 6, 0, 5, 6, 9, 6, 5, 0, 3,\n",
      "        3, 3, 6, 8, 0, 6, 2, 4, 2, 9, 1, 8, 4, 7, 1, 7, 6, 9, 9, 3, 3, 2, 6, 1,\n",
      "        7, 7, 5, 2, 6, 4, 9, 6, 3, 5, 3, 2, 2, 9, 7, 2, 8, 5, 7, 8, 6, 1, 3, 1,\n",
      "        4, 6, 4, 7, 5, 1, 9, 8, 7, 9, 2, 1, 5, 8, 0, 4, 5, 7, 9, 1, 9, 5, 1, 1,\n",
      "        5, 0, 7, 5, 6, 8, 0, 3, 4, 1, 1, 2, 1, 4, 3, 9, 1, 6, 2, 4, 4, 1, 4, 4,\n",
      "        8, 1, 2, 6, 3, 3, 9, 0])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09823f9-eac7-4464-95c6-5d95b4ba9f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0262, -0.0218,  0.0045,  ..., -0.0262, -0.0220,  0.0054],\n",
       "         [ 0.0018,  0.0246,  0.0350,  ...,  0.0060,  0.0062, -0.0151],\n",
       "         [ 0.0071, -0.0296, -0.0175,  ..., -0.0340, -0.0005, -0.0168],\n",
       "         ...,\n",
       "         [ 0.0175, -0.0272,  0.0337,  ...,  0.0201,  0.0089, -0.0300],\n",
       "         [ 0.0159, -0.0189,  0.0043,  ...,  0.0123,  0.0057,  0.0164],\n",
       "         [ 0.0266, -0.0142,  0.0314,  ..., -0.0124,  0.0049, -0.0329]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0183,  0.0021,  0.0149, -0.0112, -0.0068, -0.0029, -0.0185,  0.0344,\n",
       "          0.0310,  0.0010], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb): # Shape of xb is expected to be (batch_size, shape)\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        print(xb)\n",
    "        out = self.linear(xb)\n",
    "        print(out)\n",
    "        return(out)\n",
    "\n",
    "model = MnistModel()\n",
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060f66a1-5f41-492c-9871-00726e2ba2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[-0.3281, -0.1695,  0.0610,  ..., -0.0097,  0.0160, -0.1084],\n",
      "        [-0.0485, -0.1261, -0.1175,  ..., -0.0636, -0.1274, -0.0177],\n",
      "        [ 0.1713, -0.2009,  0.1093,  ..., -0.0641,  0.0115,  0.2335],\n",
      "        ...,\n",
      "        [ 0.1367, -0.1461, -0.2041,  ...,  0.0402,  0.1414,  0.0573],\n",
      "        [ 0.0201, -0.0689,  0.0294,  ..., -0.1718,  0.0780,  0.1033],\n",
      "        [ 0.0584,  0.0411, -0.1100,  ..., -0.0536, -0.0994, -0.0640]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c9ed15-8bcf-403a-a9b0-48c4ad7ee477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.0729, 0.0854, 0.1076, 0.1179, 0.0996, 0.1237, 0.0988, 0.1003, 0.1029,\n",
      "         0.0908],\n",
      "        [0.0997, 0.0922, 0.0930, 0.1067, 0.1072, 0.0928, 0.1153, 0.0982, 0.0921,\n",
      "         0.1028]])\n",
      "\n",
      "\n",
      "Sum:  1.0\n",
      "\n",
      "\n",
      "tensor([5, 6, 9, 7, 7, 2, 0, 6, 3, 0, 8, 8, 4, 8, 4, 7, 6, 6, 2, 7, 5, 6, 3, 6,\n",
      "        4, 6, 6, 6, 7, 6, 4, 3, 7, 7, 6, 7, 5, 8, 6, 0, 2, 6, 6, 8, 6, 6, 6, 4,\n",
      "        0, 9, 3, 6, 6, 8, 6, 6, 0, 0, 7, 2, 2, 2, 4, 0, 0, 6, 0, 0, 0, 0, 6, 7,\n",
      "        0, 0, 4, 4, 0, 2, 5, 4, 5, 0, 0, 4, 8, 6, 8, 9, 2, 3, 6, 0, 3, 3, 7, 0,\n",
      "        6, 0, 5, 0, 0, 8, 3, 9, 0, 9, 0, 5, 6, 6, 6, 0, 4, 3, 6, 6, 2, 6, 0, 7,\n",
      "        6, 4, 3, 0, 6, 8, 9, 3])\n",
      "\n",
      "\n",
      "tensor([0.1237, 0.1153, 0.1220, 0.1236, 0.1276, 0.1228, 0.1254, 0.1311, 0.1227,\n",
      "        0.1230, 0.1130, 0.1204, 0.1228, 0.1202, 0.1285, 0.1174, 0.1165, 0.1646,\n",
      "        0.1234, 0.1198, 0.1426, 0.1148, 0.1174, 0.1493, 0.1102, 0.1244, 0.1345,\n",
      "        0.1349, 0.1164, 0.1234, 0.1169, 0.1501, 0.1197, 0.1293, 0.1240, 0.1549,\n",
      "        0.1319, 0.1483, 0.1194, 0.1259, 0.1174, 0.1409, 0.1219, 0.1281, 0.1231,\n",
      "        0.1145, 0.1162, 0.1156, 0.1359, 0.1279, 0.1216, 0.1348, 0.1276, 0.1169,\n",
      "        0.1233, 0.1393, 0.1348, 0.1228, 0.1583, 0.1141, 0.1147, 0.1104, 0.1254,\n",
      "        0.1362, 0.1324, 0.1246, 0.1325, 0.1248, 0.1079, 0.1194, 0.1250, 0.1319,\n",
      "        0.1303, 0.1377, 0.1254, 0.1303, 0.1494, 0.1297, 0.1197, 0.1260, 0.1271,\n",
      "        0.1249, 0.1164, 0.1216, 0.1268, 0.1144, 0.1453, 0.1358, 0.1204, 0.1077,\n",
      "        0.1287, 0.1387, 0.1250, 0.1328, 0.1308, 0.1149, 0.1595, 0.1337, 0.1275,\n",
      "        0.1323, 0.1192, 0.1216, 0.1218, 0.1270, 0.1353, 0.1296, 0.1580, 0.1455,\n",
      "        0.1344, 0.1213, 0.1213, 0.1312, 0.1251, 0.1408, 0.1454, 0.1217, 0.1271,\n",
      "        0.1210, 0.1539, 0.1383, 0.1117, 0.1250, 0.1213, 0.1339, 0.1483, 0.1216,\n",
      "        0.1124, 0.1087], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Apply softmax for each output row\n",
    "probs = F.softmax(outputs, dim = 1)\n",
    "\n",
    "## chaecking at sample probabilities\n",
    "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
    "\n",
    "print(\"\\n\")\n",
    "## Add up the probabilities of an output row\n",
    "print(\"Sum: \", torch.sum(probs[0]).item())\n",
    "max_probs, preds = torch.max(probs, dim = 1)\n",
    "print(\"\\n\")\n",
    "print(preds)\n",
    "print(\"\\n\")\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efeb8a3e-8899-43b1-a323-37a6f26dbaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.0703)\n",
      "\n",
      "\n",
      "Loss Function:  <function cross_entropy at 0x00000216ABF9FC10>\n",
      "\n",
      "\n",
      "tensor(2.3255, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    return(torch.tensor(torch.sum(preds == labels).item()/ len(preds)))\n",
    "\n",
    "print(\"Accuracy: \",accuracy(outputs, labels))\n",
    "print(\"\\n\")\n",
    "loss_fn = F.cross_entropy\n",
    "print(\"Loss Function: \",loss_fn)\n",
    "print(\"\\n\")\n",
    "## Loss for the current batch\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33dd8e00-56c0-4c97-bf62-72bb5dea9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return(out)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) ## Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) ## Calculate the loss\n",
    "        return(loss)\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return({'val_loss':loss, 'val_acc': acc})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "    \n",
    "    def epoch_end(self, epoch,result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412ffe68-9219-4712-94bb-77b2f42b880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return(model.validation_epoch_end(outputs))\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        ## Training Phas\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        ## Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d590c688-30c7-4162-990b-88d9660abba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.319340467453003, 'val_acc': 0.11026503145694733}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09efce41-8ec8-46e3-bcbc-41a19a92accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9542, val_acc: 0.6169\n",
      "Epoch [1], val_loss: 1.6853, val_acc: 0.7368\n",
      "Epoch [2], val_loss: 1.4843, val_acc: 0.7742\n",
      "Epoch [3], val_loss: 1.3324, val_acc: 0.7925\n",
      "Epoch [4], val_loss: 1.2155, val_acc: 0.8054\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04ccd8-4c11-47a9-81a6-19d9c40fe7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1236, val_acc: 0.8153\n",
      "Epoch [1], val_loss: 1.0498, val_acc: 0.8214\n",
      "Epoch [2], val_loss: 0.9894, val_acc: 0.8260\n",
      "Epoch [3], val_loss: 0.9391, val_acc: 0.8295\n",
      "Epoch [4], val_loss: 0.8967, val_acc: 0.8325\n",
      "Epoch [0], val_loss: 0.8603, val_acc: 0.8353\n",
      "Epoch [1], val_loss: 0.8288, val_acc: 0.8374\n",
      "Epoch [2], val_loss: 0.8012, val_acc: 0.8407\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)\n",
    "history3 = fit(5, 0.001, model, train_loader, val_loader)\n",
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2faf775-e4da-4e81-aec4-93c28166df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace these values with your result\n",
    "history = [result0] + history1 + history2 + history3 + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy Vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c57713-2fea-45ad-9ed7-920fdba8957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the test dataset\n",
    "test_dataset = MNIST(root = 'data/', train = False, transform = transforms.ToTensor())\n",
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "print(\"shape: \", img.shape)\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2c91269-ec58-48d8-b11c-e99a655ab53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim = 1)\n",
    "    return(preds[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a427f246-d479-4400-9d8f-ce222fad083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7 , Predicted : 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "print('Label:', label, ', Predicted :', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb3c9089-062d-414a-a3c2-b95cc676120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6426597833633423, 'val_acc': 0.861621081829071}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size = 256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05261649-8c0f-4414-84e4-c9d771841d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525a43a1-aaef-4412-a286-af27e2a2c130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6426597833633423, 'val_acc': 0.861621081829071}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MnistModel()\n",
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model2.state_dict()\n",
    "test_loader = DataLoader(test_dataset, batch_size = 256)\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b08a4d-8ed9-4823-a9d0-253ae311a8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
